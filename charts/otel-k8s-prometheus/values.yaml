config:
  # Labels and annotations to look for when scraping.
  labels:
    - prometheus.io/scrape
    - newrelic.com/scrape
  annotations:
    - prometheus.io/scrape
    - newrelic.com/scrape

  # How often to pull metrics from discovered targets.
  interval: 30s

  jobs:
    # Scrape pods annotated or labeled with the specified annotations, as well as endpoints behind annotated services.
    podsEndpoints:
      enabled: true
    # Scrape externalName services, which may to exporters outside of the Kubernetes cluster.
    # Keep in mind that the scraper will hit the server directly, which can lead to unexpected results if the serivice
    # is distributing requests to more than one endpoint.
    external:
      enabled: true

  # Prometheus scrape configs to add to the prometheus receiver.
  # See https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
  extraScrapeConfigs: []

  # Enable the OTEL batch processor.
  batchProcessor:
    enabled: true

  # This pre-configured processor will apply some transformations to labels and values to match the conventions used by
  # New Relic. It should be enabled if you are sending data to New Relic.
  nrConventionsProcessor:
    enabled: false

  # Extra configs to use as processors for the otel collector.
  # By adding more processors here, metrics can be filtered or transformed with a high degree of flexibility:
  # - Filter: https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/filterprocessor
  # - Transform: https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/metricstransformprocessor
  # More: https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor
  extraProcessors: {}
    #filter/kube:
    #  metrics:
    #    exclude:
    #      match_type: regexp
    #      metric_names:
    #        - kube_.*

  # Configure the logging exporter, which can log to stderr all the metrics received by the collector.
  # See: https://github.com/open-telemetry/opentelemetry-collector/tree/main/exporter/loggingexporter
  loggingExporter:
    enabled: false
    loglevel: info

  # Configure the OTLP exporter, which would typically hit an in-cluster gateway collector.
  # Env var NR_LICENSE_KEY is available containing the license key.
  # See: https://github.com/open-telemetry/opentelemetry-collector/tree/main/exporter/otlpexporter
  otlpExporter:
    enabled: false
    endpoint: otlp.nr-data.net:4317
    headers:
      api-key: "${NR_LICENSE_KEY}"  # Added to the deployment's env by the chart automatically

  # Extra configs to use as exporters for the otel collector.
  # See: https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter
  extraExporters: {}

service:
  # prometheusDebug exposes a port where you can query this collector for all the metrics it has gathered in the
  # OpenMetrics format. It is useful for troubleshooting and seeing what the collector is scraping.
  prometheusDebug:
    enabled: false
    type: ClusterIP
    port: 9000
    annotations: {}

# ---

image:
  repository: otel/opentelemetry-collector-contrib
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# Whether to automatically create RBAC rules.
# This chart requires (and by default will create on its own) RBAC granting read-only (get, list, watch) permission to:
#  - nodes
#  - pods
#  - services
#  - endpoints
rbac:
  create: true

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}
